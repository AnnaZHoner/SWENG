What does this program do:
 --This is a program to analyise tweets in a given location with the intent of predicting natural disasters and deliver warnings to users of that area. 

What's inside:
 --chromeExtension Package:
       Description: This is a chrome extension to provide warning info about earthquakes around user's location.

       Files :
          Codes:
             background.js -- This is running at the background all the times(since user open chrome), contains part of the functions
                              of the extension.
             it could remember the var in popup.js
             jquery.js -- jquery library.
             pouchdb-7.0.0.min.js -- pouchdb library, connect the plugin to the IBM Cloudant.
             pouchdb.find.js   -- function plugin for pouchdb.
             popup.js -- this describe the function of popup.html. Contains mainly functions of the extension.
             
          Configuration Files :
             manifest.json -- this is the basic config file for a chrome extension, it records things like permission status,
                              files r/w status, images or icons location, running status and so on.
          HTML files :
             popup.html -- this is the page to show to the user when they click the extension icon.
             
          Images :
             image/warning.png -- this is the warning image to show when a "warning" level warning info was found.
             image/notice.png -- this is the warning image to show when a "safe" level warning info was found.
             image/dangerous.png -- this is the warning image to show when a "dangerous.png" warning info was found.
             icon/* -- this contains 4 different size icons(logos) for the extension.
             
             
             
 --dataProcessing Package:
         Description: Collection and organising of data to use multiple linear regression to create a model that can be used
              to predict the probability of a tweet being related to an earthquake and if a certain area has an earthquake happening
              based on the latest tweets.
                      
         Files :
           Code : 
              bashScriptGenerator.py --  A script that creates a .bat file that excecutes twitterscraper commands based on the 
                                         parameters defined in the script. Used for collection of training dataset.
              earthquakeDataPreprocessing.py -- A script to extract the relevant dates and entires from a given range of location 
                                                from the database file. 
              tweetContentPreprocessing.py -- Contains code that extracted and arranged the data for multiple linear regression. Saved
                                              two models to the.sav files.
              outDatedDemo.py -- Code used for a presentation.
              twitter.bat -- List of console commands to extract tweets
              
              Deployment:
                 deploymentDataProcessing.py -- The script that is constantly running.
                                                Contains funtions to deal with the database and implements the Multiple Linear Regression
                                                on the data to update the cloud with stats.
                 earthquakeProbability.sav -- Pickle file containing the sklearning LinearRegression() object. Takes the probabilities 
                                              of 10 most recent tweets and determines whether there is an earthquake.
                 textRecognitionModel.sav --  Pickle file containing the sklearning LinearRegression() object. Takes in tweet and
                                              determines probability of the tweet being related to an earthquake.
                 Procfile -- For heroku to know which file to run
                 requirements -- Packages used.
           Datafiles :
              SF_*.json -- tweets extracted by twitter.bat
              dataAroundSF.csv -- Data generated by earthquakeDataPreprocessing.py
              database.csv -- list of dates and timesand locations of earthquakes
  
  --twitter_stream_listener
          Description: files that run a twitter scraper that tracks nouns and adjectives related to earthquakes and writes out to database.

          Files:
             Code:
               twitter_credentials.py  --  generates json script for twitter credentials with random keys
               stream_filter.py -- file that filters tweets for using tweepy API and connects to IBM cloudant database.
               test.py -- general test file for connection to database.(could be ignored)

            Deployment:
                main file:
                  stream_filter.py -- The script that is running as a web application.(tweepy API keys needed)
                files required for web deployment:
                  manifest.txt -- initialising environment and default run version of program
                  Procfile -- libraries and environments required for the application
                  requirements.txt -- configurations for the application running

            Datafiles:
                tweets_san_francisco.json -- sample output  file of the tweets gathered with location 'San Francisco' or 'New York' or 
                                              other keywords related to earthquake.
                test_cloudant.json -- contains api key of cloudant database.



      

              
               
              
           
           
              
      
           
              
              
              
               
             
