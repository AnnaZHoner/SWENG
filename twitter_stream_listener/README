--twitter_stream_listener
        Description: files that run a twitter scraper that tracks nouns and adjectives related to earthquakes and writes out to database.
           
        Files:
           Code:
             twitter_credentials.py  --  generates json script for twitter credentials with random keys
             stream_filter.py -- file that filters tweets for using tweepy API and connects to IBM cloudant database.
             test.py -- general test file for connection to database.(could be ignored)
          
          Deployment:
              main file:
                stream_filter.py -- The script that is running as a web application.(tweepy API keys needed)
              files required for web deployment:
                manifest.txt -- initialising environment and default run version of program
                Procfile -- libraries and environments required for the application
                requirements.txt -- configurations for the application running
              
          Datafiles:
              tweets_san_francisco.json -- sample output  file of the tweets gathered with location 'San Francisco' or 'New York' or 
                                            other keywords related to earthquake.
              test_cloudant.json -- contains api key of cloudant database.
